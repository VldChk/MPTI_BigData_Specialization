{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext(conf=SparkConf().setAppName(\"MyApp\").setMaster(\"local\"))\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_article(line):\n",
    "    try:\n",
    "        article_id, text = unicode(line.rstrip()).split('\\t', 1)\n",
    "        text = re.sub(\"^\\W+|\\W+$\", \"\", text, flags=re.UNICODE)\n",
    "        words = re.split(\"\\W*\\s+\\W*\", text, flags=re.UNICODE)\n",
    "        return words\n",
    "    except ValueError as e:\n",
    "        return []\n",
    "    \n",
    "def parse_edge(s):\n",
    "  user, follower = s.split(\"\\t\")\n",
    "  return (int(user), int(follower))\n",
    "\n",
    "#just reading the file\n",
    "\n",
    "edges = sc.textFile(\"/data/twitter/twitter_sample_small.txt\").map(parse_edge).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to split list into ints and take 1st\n",
    "\n",
    "def separate_num(x):\n",
    "    return x[0]\n",
    "\n",
    "# defining additional variables\n",
    "d = 1\n",
    "res_str = ''\n",
    "\n",
    "# first step: we don't need entire datatset as for now, only those pairs where 12 is a follower\n",
    "e_12 = edges.filter(lambda e: e[1] == 12).cache()\n",
    "\n",
    "# simple check for simple tests, maybe 12 is already following 34?\n",
    "is_34 = e_12.filter(lambda e: e[0] == 34).cache().count()\n",
    "if is_34 > 0:\n",
    "    res_str = res_str + '12,34' \n",
    "    print res_str;\n",
    "#if no then here we go:\n",
    "else:\n",
    "    # taking those who are followed by 12\n",
    "    e_12_first = e_12.map(separate_num)\n",
    "    \n",
    "    # convert them into integers\n",
    "    e_12_c = e_12_first.collect()\n",
    "    \n",
    "    # initiating RDD for loop\n",
    "    prev_in_loop = e_12.persist()\n",
    "    \n",
    "    # filtering all pairs where edge is followed by edge followed by 12:\n",
    "    temp_in_loop = edges.filter(lambda e: e[1] in e_12_c).persist()\n",
    "    \n",
    "    # saving the join result into RDD, exchanging always in the way to place the next edge as 1st in pair\n",
    "    join = edges.filter(lambda e: e[1] in e_12_c).map(lambda e: (e[1], e[0])).join(prev_in_loop) \\\n",
    "        .map(lambda (x,y) : (y[0], (x, y[1]))).persist()\n",
    "    \n",
    "    # starting loop\n",
    "    while (True):\n",
    "        # Spark is a \"lazy- computing\" so it works based on links, by trigerring code below I do re-compute dataset\n",
    "        # based on previous result\n",
    "        e_12_first = temp_in_loop.map(separate_num).persist()\n",
    "        e_12_c = e_12_first.collect()\n",
    "        # Refreshing temp valiables and extending join loop\n",
    "        \n",
    "        temp_in_loop = edges.filter(lambda e: e[1] in e_12_c).persist()\n",
    "        join = temp_in_loop.map(lambda e: (e[1], e[0])).join(join) \\\n",
    "        .map(lambda (x,y) : (y[0], (x, y[1]))).persist()\n",
    "        \n",
    "        # Checking do we point to the end edge?\n",
    "        is_34 = temp_in_loop.filter(lambda e: e[0] == 34).cache().count()\n",
    "        if is_34 > 0:\n",
    "            result = join.filter(lambda e: e[0] == 34).take(1)\n",
    "            break;\n",
    "        # If no, keep loop until we do\n",
    "        d = d+1\n",
    "        prev_in_loop = temp_in_loop.persist()\n",
    "\n",
    "# Code above might loop a bit tricky, you need to run it and see step by step how it goes\n",
    "# Now time to parse the result of nested tuples into single string\n",
    "        \n",
    "    res_str = res_str + str(result[0][0])\n",
    "    result = result[0][1]\n",
    "    while True:\n",
    "        try:\n",
    "            Ptarget = int(result[1])\n",
    "            res_str = res_str + ',' + str(result[0]) + ',' + str(result[1])\n",
    "            break;\n",
    "        except:\n",
    "            res_str = res_str + ',' + str(result[0])\n",
    "            result = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,422,53,52,107,20,23,274,34\n"
     ]
    }
   ],
   "source": [
    "# And since recieved before string is swapped, we do swap it back\n",
    "\n",
    "vertex = res_str.split(\",\")\n",
    "\n",
    "i = len(vertex)\n",
    "j = 2\n",
    "final_str = '12'\n",
    "while (j < i + 1):\n",
    "    final_str = final_str + ',' +  vertex[i-j]\n",
    "    j = j + 1\n",
    "    \n",
    "# Result!\n",
    "\n",
    "print final_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
